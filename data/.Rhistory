install.packages("fda")
help(fda)
??fda
##
## As noted in the Preface to Ramsay, Hooker and Graves (p. v),
## the fda package includes scripts to reproduce all but one of the
## figures in the book.
##
## These figures can be found and run as follows:
##
## Not run:
scriptsDir <- system.file('scripts', package='fda')
Rscripts <- dir(scriptsDir, full.names=TRUE, pattern='R$')
fdarm <- grep('fdarm', Rscripts, value=TRUE)
chapters <- length(fdarm)
# NOTE:  If R fails in any of these scripts,
# this for loop will not end normally,
# and the abnormal termination will be displayed:
for(ch in 1:chapters){
cat('Running', fdarm[ch], '\n')
invisible(source(fdarm[ch]))
}
## End(Not run)
##
## Simple smoothing
##
girlGrowthSm <- with(growth, smooth.basisPar(argvals=age, y=hgtf, lambda=0.1))
plot(girlGrowthSm$fd, xlab="age", ylab="height (cm)",
main="Girls in Berkeley Growth Study" )
plot(deriv(girlGrowthSm$fd), xlab="age", ylab="growth rate (cm / year)",
main="Girls in Berkeley Growth Study" )
plot(deriv(girlGrowthSm$fd, 2), xlab="age",
ylab="growth acceleration (cm / year^2)",
main="Girls in Berkeley Growth Study" )
##
## Simple basis
##
bspl1.2 <- create.bspline.basis(norder=1, breaks=c(0,.5, 1))
plot(bspl1.2)
# 2 bases, order 1 = degree 0 = step functions:
# (1) constant 1 between 0 and 0.5 and 0 otherwise
# (2) constant 1 between 0.5 and 1 and 0 otherwise.
fd1.2 <- Data2fd(0:1, basisobj=bspl1.2)
op <- par(mfrow=c(2,1))
plot(bspl1.2, main='bases')
plot(fd1.2, main='fit')
par(op)
# A step function:  0 to time=0.5, then 1 after
x11()
plot(bspl1.2, main='bases')
plot(fd1.2, main='fit')
par(op)
girlGrowthSm <- with(growth, smooth.basisPar(argvals=age, y=hgtf, lambda=0.1))
x11()
plot(girlGrowthSm$fd, xlab="age", ylab="height (cm)",
main="Girls in Berkeley Growth Study" )
plot(deriv(girlGrowthSm$fd), xlab="age", ylab="growth rate (cm / year)",
main="Girls in Berkeley Growth Study" )
plot(deriv(girlGrowthSm$fd, 2), xlab="age",
ylab="growth acceleration (cm / year^2)",
main="Girls in Berkeley Growth Study" )
girlGrowthSm <- with(growth, smooth.basisPar(argvals=age, y=hgtf, lambda=0.1))
x11()
plot(girlGrowthSm$fd, xlab="age", ylab="height (cm)",
main="Girls in Berkeley Growth Study" )
x11()
plot(deriv(girlGrowthSm$fd), xlab="age", ylab="growth rate (cm / year)",
main="Girls in Berkeley Growth Study" )
x11()
plot(deriv(girlGrowthSm$fd, 2), xlab="age",
ylab="growth acceleration (cm / year^2)",
main="Girls in Berkeley Growth Study" )
girlGrowthSm$fd
girlGrowthSm
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,1)
sample(100,10)
train_T1T2T3T4_F = data_not_scaled_F[rand]
setwd("C:/Users/Luca/Desktop/Applied-Statistics-2019-master/Applied-Statistics-2019-master/data")
library(plyr)
library(dplyr)
library(mvtnorm)
library(rgl)
library(car)
library(MASS)
library(useful)
df_sample_normalized_T1T2T3T4 = read.table('../data/df_sample_normalized_percentages_as_features.txt')
data_label = df_sample_normalized_T1T2T3T4[,1:3]
data_scaled = cbind(data_label, scale(df_sample_normalized_T1T2T3T4[,4:47]))
data_not_scaled = cbind(data_label, df_sample_normalized_T1T2T3T4[,4:47])
spkr = 'F'
data_scaled_F = data_scaled %>% filter(speaker==spkr)
data_not_scaled_F = data_not_scaled %>% filter(speaker==spkr)
diphtong_labels_F = data_scaled_F[,2]
rand = sample(100,10)
train_T1T2T3T4_F = data_not_scaled_F[rand]
train_T1T2T3T4_F = data_not_scaled_F[rand,]
train_T1T2T3T4_F
rand = sample(93,10)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
rand = sample(93,10)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
train_T1T2T3T4_F
test_T1T2T3T4_F
rand = sample(93,80)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
library(caret)
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
rand = sample(93,80)
train_T1T2T3T4_F = data_scaled_F[rand,]
test_T1T2T3T4_F = data_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,4:47],
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'glm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F,
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'AdaBag',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'bag',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'glm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
library("xgboost")  # the main algorithm
library("archdata") # for the sample dataset
library("caret")    # for the confusionmatrix() function (also needs e1071 package)
library("dplyr")    # for some data preperation
library("Ckmeans.1d.dp") # for xgb.ggplot.importance
install.packages("xgboost")
install.packages("archdata")
install.packages("Ckmeans.1d.dp")
library("xgboost")  # the main algorithm
library("archdata") # for the sample dataset
library("caret")    # for the confusionmatrix() function (also needs e1071 package)
library("dplyr")    # for some data preperation
library("Ckmeans.1d.dp") # for xgb.ggplot.importance
as.numeric(c('aI','aU','OY'))
rand = sample(93,80)
train_T1T2T3T4_F = data_scaled_F[rand,]
test_T1T2T3T4_F = data_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'glm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'logreg',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,2:47],
method = 'plr',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(-3,2:47)],
method = 'plr',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'plr',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(4:47)],
method = 'plr',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'mda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
predict(model, test_T1T2T3T4_F[,4:47])
set.seed(42)
rand = sample(93,80)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'mda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
predict(model, test_T1T2T3T4_F[,4:47])
test_T1T2T3T4_F$diphthong
set.seed(42)
rand = sample(93,80)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'rda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
set.seed(42)
rand = sample(93,80)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'mda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
predict(model, test_T1T2T3T4_F[,4:47])
test_T1T2T3T4_F$diphthong
set.seed(82)
rand = sample(93,80)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'mda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
predict(model, test_T1T2T3T4_F[,4:47])
test_T1T2T3T4_F$diphthong
###########################################################################
set.seed(82)
rand = sample(93,75)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'mda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
predict(model, test_T1T2T3T4_F[,4:47])
test_T1T2T3T4_F$diphthong
###########################################################################
predict(model, test_T1T2T3T4_F[,c(2,4:47)])
test_T1T2T3T4_F$diphthong
set.seed(82)
rand = sample(93,75)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'LMT',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
predict(model, test_T1T2T3T4_F[,c(2,4:47)])
test_T1T2T3T4_F$diphthong
confusionMatrix(test_T1T2T3T4_F$diphthong , test_T1T2T3T4_F.pred)
test_T1T2T3T4_F.pred = predict(model, test_T1T2T3T4_F[,c(2,4:47)])
confusionMatrix(test_T1T2T3T4_F$diphthong , test_T1T2T3T4_F.pred)
set.seed(82)
rand = sample(186, 160)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'LMT',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
model = train(speaker ~ ., train_T1T2T3T4[,2:47],
method = 'LMT',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$speaker , test_T1T2T3T4.pred)
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'LMT',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
set.seed(82)
rand = sample(186, 100)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'LMT',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
###########################################################################
set.seed(82)
rand = sample(186, 100)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'mda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
set.seed(82)
rand = sample(186, 150)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'mda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
###########################################################################
set.seed(82)
rand = sample(93,75)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'lda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4_F.pred = predict(model, test_T1T2T3T4_F[,c(2,4:47)])
confusionMatrix(test_T1T2T3T4_F$diphthong , test_T1T2T3T4_F.pred)
# K-Fold cross validation
set.seed(82)
rand = sample(186, 150)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'mda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
###########################################################################
set.seed(82)
rand = sample(186, 150)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'lda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
###########################################################################
set.seed(82)
rand = sample(93,75)
train_T1T2T3T4_F = data_not_scaled_F[rand,]
test_T1T2T3T4_F = data_not_scaled_F[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4_F[,c(2,4:47)],
method = 'lda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4_F.pred = predict(model, test_T1T2T3T4_F[,c(2,4:47)])
confusionMatrix(test_T1T2T3T4_F$diphthong , test_T1T2T3T4_F.pred)
# K-Fold cross validation
set.seed(82)
rand = sample(186, 150)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'qda',  # nessun problema con: LMT, mda, ..
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4$diphthong , test_T1T2T3T4.pred)
###########################################################################
set.seed(82)
rand = sample(186, 150)
train_T1T2T3T4 = data_not_scaled[rand,]
test_T1T2T3T4 = data_not_scaled[-rand,]
model = train(diphthong ~ ., train_T1T2T3T4[,2:47],
method = 'lda',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
test_T1T2T3T4.pred = predict(model, test_T1T2T3T4[,2:47])
confusionMatrix(test_T1T2T3T4.pred, test_T1T2T3T4$diphthong)
